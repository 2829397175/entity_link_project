- Training Parameters: 
  - pretrained_model: /data/jiarui_ji/entity_link/MuVER/bert-base-chinese
  - dataset_path: /data/jiarui_ji/entity_link/entity_linking_project
  - bi_ckpt_path: None
  - epoch: 30
  - train_batch_size: 128
  - max_cand_len: 40
  - max_seq_len: 128
  - max_sentence_num: 10
  - learning_rate: [1e-05]
  - weight_decay: 0.01
  - warmup_ratio: 0.1
  - max_grad_norm: 1.0
  - gradient_accumulation: 1
  - merge_layers: 3
  - top_k: 0.4
  - eval_batch_size: 8
  - logging_interval: 50
  - eval_interval: 2000
  - accumulate_score: False
  - do_train: True
  - do_eval: True
  - do_test: False
  - view_expansion: False
  - test_mode: test
  - data_parallel: True
  - no_cuda: False
  - seed: 10000
  - name: distributed_multi_view
  - n_gpu: 1
  - local_rank: 0
